{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport sklearn\nimport sklearn.preprocessing\nimport datetime\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# split data in 80%/10%/10% train/validation/test sets\nvalid_set_size_percentage = 10 \ntest_set_size_percentage = 10 \n\n#display parent directory and working directory\nprint(os.path.dirname(os.getcwd())+':', os.listdir(os.path.dirname(os.getcwd())));\nprint(os.getcwd()+':', os.listdir(os.getcwd()));","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:18:04.494242Z","iopub.execute_input":"2022-07-08T06:18:04.494719Z","iopub.status.idle":"2022-07-08T06:18:15.778579Z","shell.execute_reply.started":"2022-07-08T06:18:04.494626Z","shell.execute_reply":"2022-07-08T06:18:15.777320Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import all stock prices \ndf = pd.read_csv(\"../input/nyse/prices-split-adjusted.csv\", index_col = 0)\ndf.info()\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:18:29.620505Z","iopub.execute_input":"2022-07-08T06:18:29.621662Z","iopub.status.idle":"2022-07-08T06:18:31.533839Z","shell.execute_reply.started":"2022-07-08T06:18:29.621622Z","shell.execute_reply":"2022-07-08T06:18:31.532987Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# number of different stocks\nprint('\\nnumber of different stocks: ', len(list(set(df.symbol))))\nprint(list(set(df.symbol))[:10])","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:19:36.242176Z","iopub.execute_input":"2022-07-08T06:19:36.242615Z","iopub.status.idle":"2022-07-08T06:19:36.482730Z","shell.execute_reply.started":"2022-07-08T06:19:36.242579Z","shell.execute_reply":"2022-07-08T06:19:36.481520Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:19:47.315248Z","iopub.execute_input":"2022-07-08T06:19:47.315669Z","iopub.status.idle":"2022-07-08T06:19:47.331608Z","shell.execute_reply.started":"2022-07-08T06:19:47.315635Z","shell.execute_reply":"2022-07-08T06:19:47.330249Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:20:00.195630Z","iopub.execute_input":"2022-07-08T06:20:00.196252Z","iopub.status.idle":"2022-07-08T06:20:00.440424Z","shell.execute_reply.started":"2022-07-08T06:20:00.196204Z","shell.execute_reply":"2022-07-08T06:20:00.439293Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:20:12.434913Z","iopub.execute_input":"2022-07-08T06:20:12.435351Z","iopub.status.idle":"2022-07-08T06:20:12.546531Z","shell.execute_reply.started":"2022-07-08T06:20:12.435316Z","shell.execute_reply":"2022-07-08T06:20:12.545175Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5));\nplt.subplot(1,2,1);\nplt.plot(df[df.symbol == 'EQIX'].open.values, color='red', label='open')\nplt.plot(df[df.symbol == 'EQIX'].close.values, color='green', label='close')\nplt.plot(df[df.symbol == 'EQIX'].low.values, color='blue', label='low')\nplt.plot(df[df.symbol == 'EQIX'].high.values, color='black', label='high')\nplt.title('stock price')\nplt.xlabel('time [days]')\nplt.ylabel('price')\nplt.legend(loc='best')\n#plt.show()\n\nplt.subplot(1,2,2);\nplt.plot(df[df.symbol == 'EQIX'].volume.values, color='black', label='volume')\nplt.title('stock volume')\nplt.xlabel('time [days]')\nplt.ylabel('volume')\nplt.legend(loc='best');","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:20:33.042273Z","iopub.execute_input":"2022-07-08T06:20:33.042720Z","iopub.status.idle":"2022-07-08T06:20:34.131342Z","shell.execute_reply.started":"2022-07-08T06:20:33.042684Z","shell.execute_reply":"2022-07-08T06:20:34.130216Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# function for min-max normalization of stock\ndef normalize_data(df):\n    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n    df['close'] = min_max_scaler.fit_transform(df['close'].values.reshape(-1,1))\n    return df\n\n# function to create train, validation, test data given stock data and sequence length\ndef load_data(stock, seq_len):\n    data_raw = stock.as_matrix() # convert to numpy array\n    data = []\n    \n    # create all possible sequences of length seq_len\n    for index in range(len(data_raw) - seq_len): \n        data.append(data_raw[index: index + seq_len])\n    \n    data = np.array(data);\n    valid_set_size = int(np.round(valid_set_size_percentage/100*data.shape[0]));  \n    test_set_size = int(np.round(test_set_size_percentage/100*data.shape[0]));\n    train_set_size = data.shape[0] - (valid_set_size + test_set_size);\n    \n    x_train = data[:train_set_size,:-1,:]\n    y_train = data[:train_set_size,-1,:]\n    \n    x_valid = data[train_set_size:train_set_size+valid_set_size,:-1,:]\n    y_valid = data[train_set_size:train_set_size+valid_set_size,-1,:]\n    \n    x_test = data[train_set_size+valid_set_size:,:-1,:]\n    y_test = data[train_set_size+valid_set_size:,-1,:]\n    \n    return [x_train, y_train, x_valid, y_valid, x_test, y_test]\n\n# choose one stock\ndf_stock = df[df.symbol == 'EQIX'].copy()\ndf_stock.drop(['symbol'],1,inplace=True)\ndf_stock.drop(['volume'],1,inplace=True)\n\ncols = list(df_stock.columns.values)\nprint('df_stock.columns.values = ', cols)\n\n# normalize stock\ndf_stock_norm = df_stock.copy()\ndf_stock_norm = normalize_data(df_stock_norm)\n\n# create train, test data\nseq_len = 20 # choose sequence length\nx_train, y_train, x_valid, y_valid, x_test, y_test = load_data(df_stock_norm, seq_len)\nprint('x_train.shape = ',x_train.shape)\nprint('y_train.shape = ', y_train.shape)\nprint('x_valid.shape = ',x_valid.shape)\nprint('y_valid.shape = ', y_valid.shape)\nprint('x_test.shape = ', x_test.shape)\nprint('y_test.shape = ',y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T06:21:03.795126Z","iopub.execute_input":"2022-07-08T06:21:03.796019Z","iopub.status.idle":"2022-07-08T06:21:04.257799Z","shell.execute_reply.started":"2022-07-08T06:21:03.795977Z","shell.execute_reply":"2022-07-08T06:21:04.256054Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}